[simulation_params]
custom_load:                False
custom_load_path:           algorithms
distributed_algo:           GlobalLearningGlobalUpdate-MA
network_path:				algorithms 
[RL_params]
input_size:                 103
num_actions:                25
train_type:                 e2e
wait_before_train:          5000
max_iters:                  150000
buffer_len:                 10000
batch_size:                 32
epsilon_saturation:         100000
crash_thresh:               1.3
Q_clip:                     True
train_interval:             2
update_target_interval:     8000
gamma:                      0.99
dropout_rate:               0.1
learning_rate:              2e-6
switch_env_steps:           2000000000
epsilon_model:              exponential

[distributed_RL params]
communication_interval:     100
average_connectivity:       2
